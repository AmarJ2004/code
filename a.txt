BFS
from collections import deque

def bfs(graph, start, end):
    queue = deque([[start]])
    visited = set()
    while queue:
        path = queue.popleft()
        node = path[-1]
        if node == end:
            return path
        if node not in visited:
            visited.add(node)
            queue.extend([path + [neighbor] for neighbor in graph[node]])

start_node = input("Enter a start node: ")
end_node = input("Enter a end node: ")
result = bfs(dict_gn, start_node, end_node)
print(result)

IDFS
def idfs(graph, start, end):
    queue= [(start, [start])]
    visited = set()
    while queue:
        node, path = queue.pop()
        if node == end: 
            return path
        if node not in visited:
            visited.add(node)
            queue.extend((neighbor, path + [neighbor]) 
            for neighbor in graph[node])

start_node = input("Enter a start node: ")
end_node = input("Enter a end node: ")
result = idfs(dict_gn, start_node, end_node)
print(result)

SVM
import pandas as pd
import seaborn as sea
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV
from sklearn.metrics import classification_report,accuracy_score,confusion_matrix

data = pd.read_csv('Breast_cancer_data.csv')
sea.heatmap(data.corr())

x, y = data.drop("diagnosis", axis=1), data["diagnosis"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

for kernel, params in [('linear', {}), ('rbf', {'gamma': 2})]:
    model = SVC(C=10, kernel=kernel, **params).fit(x_train, y_train)
    acc = accuracy_score(y_test, model.predict(x_test))
    print(f'accuracy({kernel}):', round(acc * 100, 2))

data = pd.read_csv('Social_Network_Ads.csv')
x, y = data.iloc[:, [2, 3]].values, data.iloc[:, 4].values
x = StandardScaler().fit_transform(x)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)

svc = SVC()
y_pred = svc.fit(x_train, y_train).predict(x_test) 
print('Accuracy:', round(accuracy_score(y_test, y_pred) * 100, 2))
print(confusion_matrix(y_test,y_pred))

#Optimization part changes
#1. SVC(kernel='linear')
#2. print(classification_report(y_test, y_pred))
#3. print(cross_val_score(svc,x,y,cv=10,scoring='accuracy').mean())
#4 set SVC(kernel='linear',C = 0.1) & print(confusion_matrix(y_test,y_pred))
#5 set SVC(kernel='rbf',gamma = 0.01)
#6 set SVC(kernel='poly',degree=2)

import pandas as pd
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

s = pd.read_csv("Stolen.csv")
x = s.iloc[:, :3].apply(LabelEncoder().fit_transform).values
y = LabelEncoder().fit_transform(s['ans'])
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

ber = BernoulliNB().fit(x_train, y_train)
y_pred = ber.predict(x_test)
print("Total mislabeled points: %d" % ((y_test != y_pred).sum()))
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

y_prob = pd.DataFrame(ber.predict_proba(x_test), columns=ber.classes_)
print(y_prob)
print("Prediction for [0,1,0]:", ber.predict([[0, 1, 0]]))
print("Probabilities for [0,1,0]:", ber.predict_proba([[0, 1, 0]]))

import pandas as pd
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

ads = pd.read_csv("Social_Network_Ads.csv")
x = ads.iloc[:, 2:4].values
y = ads.iloc[:, 4].values

clf = DecisionTreeClassifier(criterion="entropy").fit(x, y)
print(export_text(clf, feature_names=['Age', 'EstimatedSalary']))

plt.figure(figsize=(50, 50))
plot_tree(clf, feature_names=['Age', 'EstimatedSalary'], class_names=['Not Purchased', 'Purchased'], filled=True)
plt.show()

_, x_test, _, y_test = train_test_split(x, y, test_size=0.3, random_state=0)
print('Accuracy:', round(accuracy_score(y_test, clf.predict(x_test)) * 100, 2))
import pandas as pd
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
import numpy as np

data = pd.read_csv('iris_csv.csv')
x = data.iloc[:, :-1].apply(LabelEncoder().fit_transform)
y = LabelEncoder().fit_transform(data.iloc[:, -1])

ada_tree = AdaBoostClassifier(n_estimators=30, random_state=7)
tree_accuracy = cross_val_score(ada_tree, x, y, cv=10).mean()
print(f'Accuracy with Decision Trees: {tree_accuracy}')

svc = SVC(probability=True, kernel='linear', random_state=7)
ada_svc = AdaBoostClassifier(n_estimators=50, base_estimator=svc, random_state=7)
svc_accuracy = cross_val_score(ada_svc, x, y, cv=10).mean()
print(f'Accuracy with SVC: {svc_accuracy}')

